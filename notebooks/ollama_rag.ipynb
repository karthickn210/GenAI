{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a666e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model_name = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b564c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=ollama_model_name, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94965f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sky appears blue to us because of a phenomenon called scattering, which occurs when sunlight interacts with the tiny molecules of gases in the atmosphere. Here's a simplified explanation:\\n\\n1. **Sunlight enters Earth's atmosphere**: When the sun shines, it emits a wide range of electromagnetic radiation, including visible light.\\n2. **Light scatters off gas molecules**: As sunlight travels through the atmosphere, it encounters tiny molecules of gases like nitrogen (N2) and oxygen (O2). These molecules are much smaller than the wavelength of light, so they scatter the light in all directions.\\n3. **Short wavelengths scattered more**: The shorter wavelengths of visible light, such as blue and violet, are scattered more than the longer wavelengths, like red and orange. This is because the smaller gas molecules are more effective at scattering the shorter wavelengths.\\n4. **Blue light reaches our eyes**: As a result of this scattering, the blue light is distributed throughout the atmosphere and reaches our eyes from all directions. This is why the sky appears blue to us.\\n\\nSome additional factors can affect the color of the sky:\\n\\n* **Time of day**: During sunrise and sunset, the sun's rays have to travel through more of the Earth's atmosphere, which scatters the shorter wavelengths even more. This is why the sky often appears redder during these times.\\n* **Atmospheric conditions**: Dust, pollution, and water vapor in the air can also affect the color of the sky by scattering or absorbing light.\\n* **Altitude and atmospheric pressure**: The higher you go, the thinner the atmosphere becomes, which can change the apparent color of the sky.\\n\\nSo, to summarize: the sky appears blue because of the way sunlight interacts with the tiny molecules in the Earth's atmosphere, scattering shorter wavelengths like blue light more than longer wavelengths.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"why is the sky blue?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8937a856",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81bfa134",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the entire directory\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = DirectoryLoader('../data/', glob=\"**/*.txt\", loader_cls=TextLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2eed267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ded32110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading by pointing the document\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/data.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5dd19d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c525640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58dec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=ollama_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68f1cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ae4b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "if ollama_model_name == \"phi\" or ollama_model_name == \"phi:chat\":\n",
    "    # Phi-2 prompt is less flexible\n",
    "    prompt_template = \"\"\"Instruct: With this context\\n\\n{context}\\n\\nQuestion: {input}\\nOutput:\"\"\"\n",
    "\n",
    "else:\n",
    "    prompt_template = \"\"\" Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Question: {input}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "466a7bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), config={'run_name': 'format_inputs'})\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], template=' Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don\\'t know\\n    <context>\\n    {context}\\n    </context>\\n\\n    Question: {input}'))])\n",
       "| Ollama(model='llama3.1', temperature=0.1)\n",
       "| StrOutputParser(), config={'run_name': 'stuff_documents_chain'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cacea449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85cfd0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x121eace10>), config={'run_name': 'retrieve_documents'})\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), config={'run_name': 'format_inputs'})\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], template=' Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don\\'t know\\n    <context>\\n    {context}\\n    </context>\\n\\n    Question: {input}'))])\n",
       "            | Ollama(model='llama3.1', temperature=0.1)\n",
       "            | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       "  }), config={'run_name': 'retrieval_chain'})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3503c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestQuestions = [\n",
    "    \"What did the author do growing up\",\n",
    "    \"What computer did he convince his father to buy?\",\n",
    "    \"What did he do for his undergraduate thesis ?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9610aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "# set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6ce6a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/3: What did the author do growing up\n",
      "\n",
      "2/3: What computer did he convince his father to buy?\n",
      "\n",
      "3/3: What did he do for his undergraduate thesis ?\n"
     ]
    }
   ],
   "source": [
    "qa_pairs = []\n",
    "\n",
    "for index, question in enumerate(TestQuestions, start=1):\n",
    "    question = question.strip() # Clean up\n",
    "\n",
    "    print(f\"\\n{index}/{len(TestQuestions)}: {question}\")\n",
    "\n",
    "    response = retrieval_chain.invoke({\"input\": question})\n",
    "\n",
    "    qa_pairs.append((question.strip(), response[\"answer\"])) # Add to our output array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27def92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 What did the author do growing up\n",
      "\n",
      "The text doesn't explicitly state what the author did growing up, but based on the context and the mention of \"hack\" as one of the things they wanted to do when starting YC, it can be inferred that the author was interested in programming or computer-related activities from a young age. However, there is no specific information about their childhood or teenage years provided in the text.\n",
      "\n",
      "--------\n",
      "\n",
      "2/3 What computer did he convince his father to buy?\n",
      "\n",
      "Unfortunately, the text doesn't mention what computer he convinced his father to buy. It does mention that he was a graduate student at the time and had a \"grad student lifestyle\", but it doesn't specify what kind of computer or technology he was using.\n",
      "\n",
      "--------\n",
      "\n",
      "3/3 What did he do for his undergraduate thesis ?\n",
      "\n",
      "Unfortunately, the provided text does not mention what he did for his undergraduate thesis. However, it is mentioned that he later became a graduate student (presumably at Stanford) and started Viaweb with some friends, which was eventually acquired by Yahoo in 1998.\n",
      "\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (question, answer) in enumerate(qa_pairs, start=1):\n",
    "    print(f\"{index}/{len(qa_pairs)} {question}\\n\\n{answer}\\n\\n--------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c6e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16df4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
